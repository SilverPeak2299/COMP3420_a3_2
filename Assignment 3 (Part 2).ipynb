{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avv3G855AKlJ"
      },
      "source": [
        "# Assignment 3 Part 2 - Wiki Question Answering\n",
        "\n",
        "**Submission deadline:** Friday 30 May 2025, 11:55 pm\n",
        "\n",
        "**Marks:** 20 marks (20% of the total unit assessment)\n",
        "\n",
        "Unless a Special Consideration request has been submitted and approved, a 5% penalty (of the total possible mark of the task) will be applied for each day a written report or presentation assessment is not submitted, up until the 7th day (including weekends). After the 7th day, a grade of ‘0’ will be awarded even if the assessment is submitted. For example, if the assignment is worth 8 marks (of the entire unit) and your submission is late by 19 hours (or 23 hours 59 minutes 59 seconds), 0.4 marks (5% of 8 marks) will be deducted. If your submission is late by 24 hours (or 47 hours 59 minutes 59 seconds), 0.8 marks (10% of 8 marks) will be deducted, and so on. The submission time for all uploaded assessments is 11:55 pm. A 1-hour grace period will be provided to students who experience a technical concern. For any late submission of time-sensitive tasks, such as scheduled tests/exams, performance assessments/presentations, and/or scheduled practical assessments/labs, please apply for Special Consideration.\n",
        "\n",
        "\n",
        "## A Note on the Use of AI Generators\n",
        "\n",
        "In this assignment, we view AI code generators such as Copilot, CodeGPT, etc. as tools that can help you write code quickly. You are allowed to use these tools, but with some conditions. To understand what you can and cannot do, please visit these information pages provided by Macquarie University:\n",
        "\n",
        "Artificial Intelligence Tools and Academic Integrity in FSE - https://bit.ly/3uxgQP4\n",
        "\n",
        "If you choose to use these tools, make the following explicit in your submitted file as comments starting with \"Use of AI generators in this assignment\" explaining:\n",
        "\n",
        "-   What part of your code is based on the output of such tools,\n",
        "-   What tools you used,\n",
        "-   What prompts you used to generate the code or text, and\n",
        "-   What modifications you made on the generated code or text.\n",
        "\n",
        "This will help us assess your work fairly. If we observe that you have used an AI generator and you do not give the above information, you may face disciplinary action.\n",
        "\n",
        "## Objectives of This Assignment\n",
        "\n",
        "<!-- In Assignment 3 you will work on a general answer selection task. Given a question and a list of candidate sentences, the goal is to predict which sentences can be used as part of the answer. Assignment 3 Part 2 requires you to implement deep neural networks. -->\n",
        "\n",
        "In this assignment, you will work on the answer selection task using the WikiQA corpus. Given a question and a list of candidate sentences, the goal is to predict which sentences can be used to form a correct answer.  This assignment requires you to implement and evaluate a traditional text classification method (Naive Bayes) as well as deep neural networks (Siamese Network and Transformer models).\n",
        "\n",
        "\n",
        "\n",
        "The dataset is the **Wiki Question Answering corpus from Microsoft**. The provided files (`training.csv`, `dev_test.csv`, `test.csv` in `data.zip`) contain the following columns:\n",
        "\n",
        "-   `question_id`: ID for a question\n",
        "-   `question`: Text of the question\n",
        "-   `document_title`: Topic of the question\n",
        "-   `answer`: Sentence candidate for the answer\n",
        "-   `label`: 1 if the sentence is part of the answer, 0 otherwise\n",
        "\n",
        "The following code shows how to load and preview the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YwIwvzV0ALBI",
        "outputId": "0d7563a1-4779-48de-a97b-188ff4daca85"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>question</th>\n",
              "      <th>document_title</th>\n",
              "      <th>answer</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>A partly submerged glacier cave on Perito More...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>The ice facade is approximately 60 m high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>Ice formations in the Titlis glacier cave</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>A glacier cave is a cave formed within the ice...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>Glacier caves are often called ice caves , but...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  question_id                       question document_title   \n",
              "0          Q1  how are glacier caves formed?   Glacier cave  \\\n",
              "1          Q1  how are glacier caves formed?   Glacier cave   \n",
              "2          Q1  how are glacier caves formed?   Glacier cave   \n",
              "3          Q1  how are glacier caves formed?   Glacier cave   \n",
              "4          Q1  how are glacier caves formed?   Glacier cave   \n",
              "\n",
              "                                              answer  label  \n",
              "0  A partly submerged glacier cave on Perito More...      0  \n",
              "1          The ice facade is approximately 60 m high      0  \n",
              "2          Ice formations in the Titlis glacier cave      0  \n",
              "3  A glacier cave is a cave formed within the ice...      1  \n",
              "4  Glacier caves are often called ice caves , but...      0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv(\"data/training.csv\")\n",
        "dev_data = pd.read_csv(\"data/dev_test.csv\")\n",
        "test_data = pd.read_csv(\"data/test.csv\")\n",
        "train_data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCvxn37jBiye"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "* Complete the three tasks below.\n",
        "\n",
        "* Write your code inside this notebook.\n",
        "\n",
        "* Your notebook must include the running outputs of your final code.\n",
        "\n",
        "* **Submit this `.ipynb` file, containing your code and outputs, to iLearn.**\n",
        "\n",
        "## Assessment\n",
        "\n",
        "1.  Marks are based on the correctness of your code, outputs, and coding style.\n",
        "<!-- 2.  A total of **1.5 marks** (0.5 per task) are awarded globally across the assignment for good coding style: clean, modular code, meaningful variable names, and good comments. -->\n",
        "3.  Marks for each task focus only on the main implementation, **not on the data loading step**.\n",
        "4.  If outputs are missing or incorrect, up to **25% of the marks for that task** can be deducted.\n",
        "5.  See each task below for the detailed mark breakdown.\n",
        "\n",
        "## Task 1 (4 marks): Query-Focused Text Classification Using Naive Bayes\n",
        "\n",
        "* Preprocess the text data. Feel free to explore and use suitable preprocessing.\n",
        "\n",
        "* Extract features using **CountVectorizer** and **TF-IDF**.\n",
        "\n",
        "* Train and evaluate a **Naive Bayes classifier** on both feature sets.\n",
        "\n",
        "* Report and compare accuracy, precision, recall, and F1-score.\n",
        "\n",
        "**Mark breakdown:**\n",
        "\n",
        "\n",
        "* (2 marks) Correct implementation: preprocessing, feature extraction, training Naive Bayes models.\n",
        "\n",
        "* (1.5 marks) Proper evaluation: accuracy, precision, recall, F1-score + discussion of results.\n",
        "\n",
        "* (0.5 mark) Good coding style: clean, modular, clear variables, comments.\n",
        "\n",
        "<!-- * (0.5 mark) Preprocessing and feature extraction.\n",
        "\n",
        "* (1 mark) Training Naive Bayes on CountVectorizer and TF-IDF features.\n",
        "\n",
        "* (1 mark) Evaluation on the test set with proper metrics.\n",
        "\n",
        "* (1 mark) Brief discussion on which feature set performed better and why.\n",
        "\n",
        "* (0.5 mark) For good coding style: clean, modular code, meaningful variable names, and good comments. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtekpzwCBjMg"
      },
      "outputs": [],
      "source": [
        "#   Write your code and answers here. You can add more code and markdown cells if needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HxonZ2qFzNm"
      },
      "source": [
        "## Task 2 (6 marks): Siamese Neural Network with Contrastive Loss (PyTorch)\n",
        "\n",
        "This task involves two stages: first learning sentence embeddings using contrastive loss, and then using these embeddings for classification.\n",
        "\n",
        "### Task 2a: Learning Embeddings with Contrastive Loss\n",
        "\n",
        "* Preprocess question-answer pairs (e.g., TF-IDF or embeddings).\n",
        "\n",
        "* Implement a Siamese Network in PyTorch:\n",
        "    * The network should take the preprocessed question and answer representations as input.\n",
        "  \n",
        "    * Each branch of the Siamese network should contain two hidden layers with ReLU activation. (hidden layer size chosen from {64, 128, 256})\n",
        "  \n",
        "    * Use Euclidean-distance-based contrastive loss, use a margin value of m=1.\n",
        "  \n",
        "    * The network should output an embedding vector (the output of the second hidden layer) for the question and the answer.\n",
        "\n",
        "* Train the model and evaluate on the test set.\n",
        "\n",
        "*Note: Save the best performing model to be reused in Task 2b*\n",
        "\n",
        "### Task 2b: Classification using Learned Embeddings\n",
        "\n",
        "* Load the weights of the best performing Siamese network model saved from Task 2a. Freeze the weights of the shared Siamese branches (i.e., the hidden layers) so they are not updated during this stage.\n",
        "\n",
        "* Build Classifier Head in PyTorch:\n",
        "    * Pass the question and answer representations through their respective frozen branches to obtain their learned embeddings from Task 2a.\n",
        "\n",
        "    * Calculate the Euclidean distance between the question embedding and the answer embedding.\n",
        "\n",
        "    * Add a final classification output layer: Pass the calculated distance through a simple trainable layer (e.g., a Dense layer with 1 unit) followed by a Sigmoid activation function. This will output a value between 0 and 1, representing the predicted probability of the pair being related.\n",
        "\n",
        "* Train the model and evaluate on the test set with Binary Cross-Entropy (BCE) loss.\n",
        "\n",
        "* Report the accuracy and provide at least one failure case analysis, with supporting code output.\n",
        "\n",
        "**Mark breakdown:**\n",
        "\n",
        "* (3 marks) Correct implementation: Siamese NN architecture, contrastive loss, classification head setup.\n",
        "\n",
        "* (2.5 marks) Proper evaluation: training/evaluation correctness, metric reporting, failure case analysis.\n",
        "\n",
        "* (0.5 mark) Good coding style: : clean, modular code, meaningful variable names, and good comments.\n",
        "\n",
        "<!-- * (1 mark) Correct Siamese NN architecture and contrastive loss.\n",
        "\n",
        "* (1 mark) SNN training setup and data feeding.\n",
        "\n",
        "* (1 mark) Correctly loading the pre-trained model, freezing the appropriate layers, and constructing the classification architecture.\n",
        "\n",
        "* (1 mark) Correct training/evaluation setup using Binary Cross-Entropy loss.\n",
        "\n",
        "* (0.5 mark) Proper evaluation and accuracy reporting.\n",
        "\n",
        "* (1 mark) Example of a failure case, possible reason, and suggested improvement.\n",
        "\n",
        "* (0.5 mark) For good coding style: clean, modular code, meaningful variable names, and good comments. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIbUH_NTBuO0"
      },
      "outputs": [],
      "source": [
        "#   Write your code and answers here. You can add more code and markdown cells if needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSPdEV5bFzNm"
      },
      "source": [
        "## Task 3 (10 marks): Transformer-Based Sentence Classification (PyTorch)\n",
        "\n",
        "* Preprocess input as: question [SEP] answer, pad to a fixed length (justify your choice of length).\n",
        "\n",
        "* Use a suitable tokenizer (justify your choice).\n",
        "\n",
        "* Build a Transformer model in PyTorch:\n",
        "\n",
        "    * Embedding layer (size 128) + positional embeddings.\n",
        "\n",
        "    * One Transformer encoder layer (hidden dim in {64, 128, 256}, 4 attention heads).\n",
        "\n",
        "    * One hidden layer (256 units, ReLU).\n",
        "\n",
        "    * Use suitable final layer for classification\n",
        "    \n",
        "  \n",
        "* Apply Global Average Pooling to the output sequence of the Transformer encoder layer.\n",
        "  \n",
        "* Use an appropriate loss function (e.g., CrossEntropyLoss).\n",
        "\n",
        "* Train and evaluate on the test split.\n",
        "\n",
        "* Report best accuracy, precision, recall, F1-score, and discuss a failure case, with supporting code output.\n",
        "\n",
        "**Mark breakdown:**\n",
        "\n",
        "* (5 marks) Correct implementation: input preparation, tokenizer, transformer model, training setup.\n",
        "\n",
        "* (4.5 marks) Proper evaluation: metric reporting, failure case analysis with discussion.\n",
        "\n",
        "* (0.5 mark) Good coding style: : clean, modular code, meaningful variable names, and good comments.\n",
        "\n",
        "<!-- * (1.5 marks) Correct input preparation and tokenizer choice (with justification).\n",
        "\n",
        "* (2 marks) Transformer architecture implementation.\n",
        "\n",
        "* (2 marks) Training setup, loss function, and optimizer.\n",
        "\n",
        "* (2 marks) Evaluation and correct metric reporting.\n",
        "\n",
        "* (2 marks) Failure case analysis and suggestions.\n",
        "\n",
        "* (0.5 mark) For good coding style: clean, modular code, meaningful variable names, and good comments. -->\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KvddjdYB1ln"
      },
      "outputs": [],
      "source": [
        "#   Write your code and answers here. You can add more code and markdown cells if needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWRYOTk8B5oB"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Your submission should consist of this Jupyter notebook with all your code and explanations inserted into the notebook as text cells. **The notebook should contain the output of the runs. All code should run. Code with syntax errors or code without output will not be assessed.**\n",
        "\n",
        "**Do not submit multiple files.**\n",
        "\n",
        "Examine the text cells of this notebook so that you can have an idea of how to format text for good visual impact. You can also read this useful [guide to the MarkDown notation](https://daringfireball.net/projects/markdown/syntax),  which explains the format of the text cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx7RGfmj0QGH"
      },
      "source": [
        "### Marking Rubric\n",
        "\n",
        "| Criteria                          | Unsatisfactory | Pass           | Credit         | Distinction     |\n",
        "|----------------------------------|----------------|----------------|----------------|-----------------|\n",
        "| **Task 1 – Correctness**         | 0 points       | 1 point        | 1.5 points     | 2 points        |\n",
        "| **Task 1 – Evaluation & Discussion** | 0 points   | 0.75 points    | 1 point        | 1.5 points      |\n",
        "| **Task 1 – Code Readability**    | 0 points       | 0.25 points    | 0.4 points     | 0.5 points      |\n",
        "| **Task 2 – Correctness**         | 0 points       | 1.5 points     | 2.5 points     | 3 points        |\n",
        "| **Task 2 – Evaluation & Analysis** | 0 points     | 1.25 points    | 2 points       | 2.5 points      |\n",
        "| **Task 2 – Code Readability**    | 0 points       | 0.25 points    | 0.4 points     | 0.5 points      |\n",
        "| **Task 3 – Correctness**         | 0 points       | 2.5 points     | 4 points       | 5 points        |\n",
        "| **Task 3 – Evaluation & Analysis** | 0 points     | 2.25 points    | 3.5 points     | 4.5 points      |\n",
        "| **Task 3 – Code Readability**    | 0 points       | 0.25 points    | 0.4 points     | 0.5 points      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBuHLYX00pUs"
      },
      "source": [
        "### Assessment Criteria Description\n",
        "\n",
        "The following aspects will be considered when marking each task. The total score is based on the level of achievement across these dimensions.\n",
        "\n",
        "#### Correctness\n",
        "How well the main functionality and requirements of the task are implemented.\n",
        "\n",
        "- **Unsatisfactory** – Major components are missing or incorrect.\n",
        "- **Pass** – Some core components are correctly implemented.\n",
        "- **Credit** – Most components are correctly implemented with minor issues.\n",
        "- **Distinction** – All required components are correctly and completely implemented.\n",
        "\n",
        "#### Evaluation & Analysis (where applicable)\n",
        "The quality of evaluation metrics, observations, and insights into the model’s performance.\n",
        "\n",
        "- **Unsatisfactory** – Minimal or no evaluation and discussion.\n",
        "- **Pass** – Basic evaluation is provided, but analysis is shallow.\n",
        "- **Credit** – Good evaluation with meaningful discussion.\n",
        "- **Distinction** – In-depth, insightful analysis and thoughtful observations.\n",
        "\n",
        "#### Code Readability\n",
        "Clarity, structure, and quality of code writing style.\n",
        "\n",
        "- **Unsatisfactory** – Code is difficult to read, poorly structured, and lacks clarity (e.g., meaningless variable names, no comments).\n",
        "- **Pass** – Code is generally readable with some good practices.\n",
        "- **Credit** – Code is clearly readable and mostly well-structured.\n",
        "- **Distinction** – Code is clean, well-organized, and easy to follow; shows excellent style and best practices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rijR3OF9B6AX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
